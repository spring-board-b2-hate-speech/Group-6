{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries and Loading the Data"
      ],
      "metadata": {
        "id": "EEyYgFpeLaBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/HateSpeechDetection (Balanced dataset).csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quM3aAWrLZm-",
        "outputId": "ef156806-d2dc-4cd1-bf31-d2f012ff8d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform                                            Comment  Hateful\n",
            "0   Reddit  Damn I thought they had strict gun laws in Ger...        0\n",
            "1   Reddit  I dont care about what it stands for or anythi...        0\n",
            "2   Reddit                  It's not a group it's an idea lol        0\n",
            "3   Reddit                          So it's not just America!        0\n",
            "4   Reddit  The dog is a spectacular dancer considering he...        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:"
      ],
      "metadata": {
        "id": "vl-VMMWZLtu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the comments\n",
        "df['Comment'] = df['Comment'].apply(preprocess_text)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddDo_ZJGLvGi",
        "outputId": "06890b16-7916-4671-9d1f-1132e0128046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform                                           Comment  Hateful\n",
            "0   Reddit              damn thought strict gun laws germany        0\n",
            "1   Reddit  dont care stands anything connected like shields        0\n",
            "2   Reddit                                    group idea lol        0\n",
            "3   Reddit                                           america        0\n",
            "4   Reddit  dog spectacular dancer considering two left feet        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Data:"
      ],
      "metadata": {
        "id": "KyUTavXhLyu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and labels\n",
        "X = df['Comment']\n",
        "y = df['Hateful']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training samples: {len(X_train)}')\n",
        "print(f'Testing samples: {len(X_test)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSjBKJQuL0S4",
        "outputId": "cec738c4-45c3-4503-c33a-1f6f71ac4e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 2400\n",
            "Testing samples: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the Text Data"
      ],
      "metadata": {
        "id": "l7HXZdc-L5ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "3bXQDTL_L639"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluating Different Models"
      ],
      "metadata": {
        "id": "9faB7W4BMBXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "UtdV-eStMHu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lr_predictions = lr_model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "print('Logistic Regression Accuracy:', lr_accuracy)\n",
        "print(classification_report(y_test, lr_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXkoD0ETMG_P",
        "outputId": "c4dc5f92-b77e-4466-d6cb-64fb5bc09ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.8816666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       494\n",
            "           1       1.00      0.33      0.50       106\n",
            "\n",
            "    accuracy                           0.88       600\n",
            "   macro avg       0.94      0.67      0.71       600\n",
            "weighted avg       0.90      0.88      0.86       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine"
      ],
      "metadata": {
        "id": "QjLL4MXoMOxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Support Vector Machine model\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions\n",
        "svm_predictions = svm_model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
        "print('Support Vector Machine Accuracy:', svm_accuracy)\n",
        "print(classification_report(y_test, svm_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWt3_ir5MPuK",
        "outputId": "f48c8856-59cc-4c1a-a919-9dbde2cab9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine Accuracy: 0.91\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       494\n",
            "           1       0.98      0.50      0.66       106\n",
            "\n",
            "    accuracy                           0.91       600\n",
            "   macro avg       0.94      0.75      0.81       600\n",
            "weighted avg       0.92      0.91      0.90       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "U1w-d6Y_MVTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_predictions = rf_model.predict(X_test_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print('Random Forest Accuracy:', rf_accuracy)\n",
        "print(classification_report(y_test, rf_predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXILae4UMWdB",
        "outputId": "71d38a2d-b8f9-46f7-bde0-7daa547e654e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.94\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       494\n",
            "           1       0.94      0.71      0.81       106\n",
            "\n",
            "    accuracy                           0.94       600\n",
            "   macro avg       0.94      0.85      0.89       600\n",
            "weighted avg       0.94      0.94      0.94       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Model Performance:"
      ],
      "metadata": {
        "id": "BRi5OcIiMceH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model Performance Summary:')\n",
        "print(f'Logistic Regression Accuracy: {lr_accuracy}')\n",
        "print(f'Support Vector Machine Accuracy: {svm_accuracy}')\n",
        "print(f'Random Forest Accuracy: {rf_accuracy}')\n"
      ],
      "metadata": {
        "id": "Sxj7T46UMebl",
        "outputId": "1ab392b7-e425-4888-9690-7ce0f9936d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Summary:\n",
            "Logistic Regression Accuracy: 0.8816666666666667\n",
            "Support Vector Machine Accuracy: 0.91\n",
            "Random Forest Accuracy: 0.94\n"
          ]
        }
      ]
    }
  ]
}