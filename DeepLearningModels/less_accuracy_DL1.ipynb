{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries and Loading the Data:\n"
      ],
      "metadata": {
        "id": "MoiB1zsGlUcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Conv1D, MaxPooling1D, Dense, Dropout, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/HateSpeechDetection (Balanced dataset).csv'  # Update the file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsTWAC43laBd",
        "outputId": "15d620bc-1955-4d51-ac55-341d9c7f5c41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform                                            Comment  Hateful\n",
            "0   Reddit  Damn I thought they had strict gun laws in Ger...        0\n",
            "1   Reddit  I dont care about what it stands for or anythi...        0\n",
            "2   Reddit                  It's not a group it's an idea lol        0\n",
            "3   Reddit                          So it's not just America!        0\n",
            "4   Reddit  The dog is a spectacular dancer considering he...        0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing:"
      ],
      "metadata": {
        "id": "y5_QDtOzlxcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the comments\n",
        "df['Comment'] = df['Comment'].apply(preprocess_text)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p9sSk_tly1G",
        "outputId": "3525d04e-b856-4891-d341-f8f871c07b3f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform                                           Comment  Hateful\n",
            "0   Reddit              damn thought strict gun laws germany        0\n",
            "1   Reddit  dont care stands anything connected like shields        0\n",
            "2   Reddit                                    group idea lol        0\n",
            "3   Reddit                                           america        0\n",
            "4   Reddit  dog spectacular dancer considering two left feet        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Padding"
      ],
      "metadata": {
        "id": "3m9NuqQrl4nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and labels\n",
        "X = df['Comment']\n",
        "y = df['Hateful']\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_tokenized = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# Pad the sequences\n",
        "max_length = 100  # Define the maximum length for padding\n",
        "X_padded = pad_sequences(X_tokenized, maxlen=max_length, padding='post')\n",
        "\n",
        "# Display the shape of the padded data\n",
        "print(f'Padded data shape: {X_padded.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRlPw9aSl8FC",
        "outputId": "84e9de6e-76e2-44df-8010-e4a11f48d83d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded data shape: (3000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Data:"
      ],
      "metadata": {
        "id": "AoiYbxm2mDOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training samples: {len(X_train)}')\n",
        "print(f'Testing samples: {len(X_test)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esNsSl1mmEjF",
        "outputId": "608dc566-a7de-4706-bf3a-357666f2f706"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 2400\n",
            "Testing samples: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Building the Model:"
      ],
      "metadata": {
        "id": "yzY5efcOmIkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "embedding_dim = 128  # Dimension of the embedding vectors\n",
        "model = Sequential()\n",
        "\n",
        "# Add embedding layer\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim, input_length=max_length))\n",
        "\n",
        "# Add spatial dropout layer\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "\n",
        "# Add convolutional layer\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "# Add LSTM layer\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Add dense layers\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci3lp0gcmLzn",
        "outputId": "ba0e2f60-5737-4fb9-b269-f02906de1bad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          792704    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 100, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 64)            41024     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 48, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               66000     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 909929 (3.47 MB)\n",
            "Trainable params: 909929 (3.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model:"
      ],
      "metadata": {
        "id": "DuzKj4zYmRzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwOz8_10mUei",
        "outputId": "237c7094-4560-425c-df1a-6eb73a345806"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "60/60 [==============================] - 14s 159ms/step - loss: 0.5213 - accuracy: 0.7948 - val_loss: 0.5078 - val_accuracy: 0.7958\n",
            "Epoch 2/5\n",
            "60/60 [==============================] - 8s 128ms/step - loss: 0.5161 - accuracy: 0.7937 - val_loss: 0.5062 - val_accuracy: 0.7958\n",
            "Epoch 3/5\n",
            "60/60 [==============================] - 9s 145ms/step - loss: 0.5143 - accuracy: 0.7937 - val_loss: 0.5077 - val_accuracy: 0.7958\n",
            "Epoch 4/5\n",
            "60/60 [==============================] - 9s 153ms/step - loss: 0.5190 - accuracy: 0.7937 - val_loss: 0.5073 - val_accuracy: 0.7958\n",
            "Epoch 5/5\n",
            "60/60 [==============================] - 7s 118ms/step - loss: 0.5130 - accuracy: 0.7937 - val_loss: 0.5075 - val_accuracy: 0.7958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the Model:"
      ],
      "metadata": {
        "id": "IDJjpKTWmWTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhtFSagwmY8Q",
        "outputId": "7f8218dd-8e4b-4166-a6e0-d13a2b9b8ce7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 2s 68ms/step\n",
            "19/19 [==============================] - 3s 55ms/step - loss: 0.6902 - accuracy: 0.8233\n",
            "Test Accuracy: 0.8233333230018616\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90       494\n",
            "           1       0.00      0.00      0.00       106\n",
            "\n",
            "    accuracy                           0.82       600\n",
            "   macro avg       0.41      0.50      0.45       600\n",
            "weighted avg       0.68      0.82      0.74       600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}