{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " LABEL ENCODING method and FREQUENCY ENCODING method resulted in the same higher accuracy (0.9283), while the ONEHOT ENCODING method had a lower accuracy (0.8733), we can finalize one of the better-performing methods.\n",
        "\n",
        "Since both the first and third methods achieved the same accuracy, we can choose either based on additional factors such as interpretability and simplicity."
      ],
      "metadata": {
        "id": "M-T0O8kKKDFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Chosen Method:\n",
        "Label Encoding and Count Vectorization\n",
        "\n",
        "Reasons for choosing this method:\n",
        "\n",
        "\n",
        "High Accuracy : Achieved a high accuracy of 0.9283.\n",
        "\n",
        "Simplicity : Easy to implement and understand.\n",
        "\n",
        "Efficiency : Count Vectorization is computationally less intensive than TF-IDF."
      ],
      "metadata": {
        "id": "d_raDdlRLjGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Load the Dataset\n",
        "\n",
        "We start by loading the dataset using pandas, a powerful data manipulation library. This step is crucial to understand the structure and contents of the data."
      ],
      "metadata": {
        "id": "xe1kGC3sLzUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/HateSpeechDetection (preprocessed).csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7HB-VC5L7Wu",
        "outputId": "8b9dc9c6-9669-44ad-b2b7-3b5275b709f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform                                            Comment  Hateful\n",
            "0   Reddit  Damn I thought they had strict gun laws in Ger...        0\n",
            "1   Reddit  I dont care about what it stands for or anythi...        0\n",
            "2   Reddit                  It's not a group it's an idea lol        0\n",
            "3   Reddit                          So it's not just America!        0\n",
            "4   Reddit  The dog is a spectacular dancer considering he...        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2:\n",
        "\n",
        "\n",
        "Encode the 'Platform' Column using Label Encoding\n",
        "\n",
        "Label Encoding transforms categorical values into integers. This is particularly useful for machine learning algorithms that cannot work with categorical data directly."
      ],
      "metadata": {
        "id": "NEKr-RDkMI80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Label Encode the 'Platform' column\n",
        "label_encoder = LabelEncoder()\n",
        "data['Platform_encoded'] = label_encoder.fit_transform(data['Platform'])\n",
        "\n",
        "# Display the encoded platform data\n",
        "print(data[['Platform', 'Platform_encoded']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90j6BN-jMNId",
        "outputId": "a80cf833-9838-460a-c05f-4c1ffbe2e470"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Platform  Platform_encoded\n",
            "0   Reddit                 1\n",
            "1   Reddit                 1\n",
            "2   Reddit                 1\n",
            "3   Reddit                 1\n",
            "4   Reddit                 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "To convert the Platform column into a numerical format.\n",
        "\n",
        "Label Encoding:\n",
        "Assigns a unique integer to each category.\n",
        "\n",
        "For example, if Platform has values like Reddit, Twitter, and Facebook, they might be encoded as 0, 1, and 2 respectively.\n",
        "\n",
        "Output:\n",
        "A new column Platform_encoded in the DataFrame."
      ],
      "metadata": {
        "id": "FIum0oxUOG3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3:\n",
        "\n",
        "\n",
        "Encode the 'Comment' Column using Count Vectorization.\n",
        "\n",
        "\n",
        "\n",
        "Count Vectorization converts the text into a matrix of token counts. Each word in the text is represented as a feature."
      ],
      "metadata": {
        "id": "4VCBjzL7MS6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorize the 'Comment' column\n",
        "count_vectorizer = CountVectorizer(max_features=5000)\n",
        "comments_count = count_vectorizer.fit_transform(data['Comment']).toarray()\n",
        "\n",
        "# Convert to DataFrame\n",
        "comments_count_df = pd.DataFrame(comments_count, columns=count_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Display the encoded comments data\n",
        "print(comments_count_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m0eZxYnMYAd",
        "outputId": "a40d7175-380f-428c-c130-7a0768739244"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   000  00am  02  10  100  1000001  100k  105  10days  10k  ...  zipped  \\\n",
            "0    0     0   0   0    0        0     0    0       0    0  ...       0   \n",
            "1    0     0   0   0    0        0     0    0       0    0  ...       0   \n",
            "2    0     0   0   0    0        0     0    0       0    0  ...       0   \n",
            "3    0     0   0   0    0        0     0    0       0    0  ...       0   \n",
            "4    0     0   0   0    0        0     0    0       0    0  ...       0   \n",
            "\n",
            "   zipper  zoe  zombie  zone  zonked  zoology  zoomies  zuckerberg  äôt  \n",
            "0       0    0       0     0       0        0        0           0    0  \n",
            "1       0    0       0     0       0        0        0           0    0  \n",
            "2       0    0       0     0       0        0        0           0    0  \n",
            "3       0    0       0     0       0        0        0           0    0  \n",
            "4       0    0       0     0       0        0        0           0    0  \n",
            "\n",
            "[5 rows x 5000 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "To convert the text data into numerical features.\n",
        "\n",
        "Count Vectorization:\n",
        "Creates a matrix where each row represents a comment, and each column represents a word (feature) with the count of its occurrences.\n",
        "\n",
        "max_features=5000:\n",
        " Limits the number of features to 5000 to manage computational complexity.\n",
        "\n",
        "Output:\n",
        "A DataFrame comments_count_df with word counts as features."
      ],
      "metadata": {
        "id": "XbpJ8VPfOdag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4:\n",
        "\n",
        "\n",
        "Combine Encoded Features.\n",
        "\n",
        "\n",
        "We merge the encoded Platform column and the count vectorized Comment data into a single DataFrame."
      ],
      "metadata": {
        "id": "tbO4UXdzMmJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all features into a single DataFrame\n",
        "encoded_data = pd.concat([comments_count_df, data['Platform_encoded']], axis=1)\n",
        "encoded_data['Hateful'] = data['Hateful']\n",
        "\n",
        "# Display the combined encoded data\n",
        "print(encoded_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EWnfVmBMoss",
        "outputId": "03d1e9b8-7e5c-47ae-f567-7aada34ef847"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   000  00am  02  10  100  1000001  100k  105  10days  10k  ...  zoe  zombie  \\\n",
            "0    0     0   0   0    0        0     0    0       0    0  ...    0       0   \n",
            "1    0     0   0   0    0        0     0    0       0    0  ...    0       0   \n",
            "2    0     0   0   0    0        0     0    0       0    0  ...    0       0   \n",
            "3    0     0   0   0    0        0     0    0       0    0  ...    0       0   \n",
            "4    0     0   0   0    0        0     0    0       0    0  ...    0       0   \n",
            "\n",
            "   zone  zonked  zoology  zoomies  zuckerberg  äôt  Platform_encoded  Hateful  \n",
            "0     0       0        0        0           0    0                 1        0  \n",
            "1     0       0        0        0           0    0                 1        0  \n",
            "2     0       0        0        0           0    0                 1        0  \n",
            "3     0       0        0        0           0    0                 1        0  \n",
            "4     0       0        0        0           0    0                 1        0  \n",
            "\n",
            "[5 rows x 5002 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "To prepare the dataset for model training by combining all numerical features.\n",
        "\n",
        "Concat:\n",
        "Merges the DataFrames horizontally.\n",
        "\n",
        "Output:\n",
        "A DataFrame encoded_data with numerical features ready for machine learning."
      ],
      "metadata": {
        "id": "O27dQuy2O5du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5:\n",
        "\n",
        "\n",
        "Training and Evaluating a Machine Learning Model.\n",
        "\n",
        "\n",
        "We use Logistic Regression, a widely used linear model for binary classification tasks. We split the data into training and testing sets, train the model, and evaluate its performance."
      ],
      "metadata": {
        "id": "_whfn8kFMvlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = encoded_data.drop('Hateful', axis=1)\n",
        "y = encoded_data['Hateful']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdDaq9THM1wR",
        "outputId": "9117859f-ab1b-4293-a74c-cb8c04154aa0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9283333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       494\n",
            "           1       0.97      0.61      0.75       106\n",
            "\n",
            "    accuracy                           0.93       600\n",
            "   macro avg       0.95      0.80      0.85       600\n",
            "weighted avg       0.93      0.93      0.92       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "To build and evaluate a predictive model.\n",
        "\n",
        "Logistic Regression:\n",
        "A simple yet effective model for binary classification.\n",
        "\n",
        "max_iter=1000:\n",
        "Increases the maximum number of iterations for convergence.\n",
        "\n",
        "Train-Test Split:\n",
        "Divides the data into training (80%) and testing (20%) sets to evaluate model performance.\n",
        "\n",
        "Metrics:\n",
        "\n",
        "Accuracy:\n",
        "Proportion of correctly predicted instances.\n",
        "\n",
        "Classification Report:\n",
        "Provides precision, recall, and F1-score for both classes (hateful and non-hateful)."
      ],
      "metadata": {
        "id": "CJBFm6K_POsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "why this method is effective:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Label Encoding:\n",
        "\n",
        "\n",
        "Efficiently converts the categorical Platform column into numerical values without adding extra dimensions.\n",
        "\n",
        "\n",
        "Count Vectorization:\n",
        "\n",
        "\n",
        "Effectively captures the frequency of words in the Comment column, making it suitable for text classification tasks.\n",
        "\n",
        "\n",
        "Logistic Regression:\n",
        "\n",
        "\n",
        "A robust and simple linear model that works well with the encoded features."
      ],
      "metadata": {
        "id": "i7T2iLVQNMWz"
      }
    }
  ]
}